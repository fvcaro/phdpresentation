\begin{frame}{Monte Carlo integration}
\begin{center}
$
\ds \int_a^b f(x) dx \approx \frac{b-a}{N} \sum_{i=1}^N f(X_i), \;
$
where $X \sim Uniform(a,b)$
\end{center}

\begin{itemize}
\item[\tickYes] Convergence rate independent of the dimension: $\mathcal{O}(N^{-1/2})$
\item[\tickNo] Slow convergence in low dimensions (1D, 2D, 3D)
\item[\tickYes] Appropriate for high dimensions
\item[\tickYes] Mesh-free method
\item[\tickYes] Allows the use of autodiff to compute $\nabla u$
\item[\tickYes] Easy to implement
\item[\tickYes] Exploit the use of minibatches and GPUs
\end{itemize}
\end{frame}


\begin{frame}{Explainability of the NN: Regularization methods}
\centering

\begin{itemize}
\item We  minimise the loss:
$$\mathcal{L}_{total} = \mathcal{L}_{Ritz}+R.$$
\vspace{0.2cm}

\item Using arguments similar to (Mishra \textit{et al.}, 2020), we define $R$ for a simple NN as:

\begin{equation*}
R\left(\theta, u_{NN}(x_i), \dfrac{\partial^{n}u_{NN}(x_i) }{\partial x^{n}} \right).
\end{equation*}


\vspace{0.2cm}
\item $R$ acts as a regularizer, penalising poor quadrature via the loss. 
%\vspace{0.2cm}
%\item $\mathcal{R}\sim \frac{1}{N}$, so for $N$ large, the ``bias" from $\mathcal{R}$ vanishes.
%

\vspace{0.5cm}

%\beamertemplatebookbibitems
\begin{thebibliography}{1}
%\bibitem{Author1990}A. Author. \newblock\emph{Handbook of Everything}.\newblock
%Some Press, 1990.\beamertemplatearticlebibitems
\bibitem{Mishra}Mishra, S., Molinaro, R.: Estimates on the generalization error of physics informed neural
networks (PINNs) for approximating PDEs. ArXiv:2006.16144 (2020).
\end{thebibliography}
\end{itemize}
\end{frame}


\begin{frame}{Explainability of the NN: Regularization methods}
\vspace{0.25cm}
\begin{itemize}
\item[\tickYes]The loss prohibits overfitting
\vspace{0.15cm}

\item[\tickYes] We have {\it a posteriori} estimation of quadrature error
\vspace{0.15cm}

\item[\tickYes] $R$ is computationally cheap to evaluate
\vspace{0.15cm}
%
%\item[\tickNo] If $N$ is small, the problem is drastically changed by $R$
%\vspace{0.15cm}

\item[\tickNo] Finding an expression for $R$ is difficult and problem dependent
\vspace{0.15cm}

\item[\tickNo] Only valid for regular integrands
\end{itemize}
\end{frame}


\begin{frame}{Adaptive Integration}
\only<1-1>{
\centering
\begin{columns}
\begin{column}{0.7\textwidth}
	\begin{figure}[!htp]
		\input{Diapos/PDEs_with_NN/Figures/Quadrature_problem/Adaptive/Adaptive_1b.tex}
		\label{fig:adaptive_1}
 	\end{figure}
\end{column}

\begin{column}{0.3\textwidth}
Training set

\vspace{2.5cm}

Validation set
\end{column}
\end{columns}
 }

\only<2-2>{
\centering
\begin{columns}
\begin{column}{0.7\textwidth}
	\begin{figure}[!htp]
		\input{Diapos/PDEs_with_NN/Figures/Quadrature_problem/Adaptive/Adaptive_2b.tex}
		\label{fig:adaptive_1}
 	\end{figure}
\end{column}

\begin{column}{0.3\textwidth}
Training set

\vspace{2.5cm}

Validation set
\end{column}
\end{columns}
 }

\only<3-3>{
\centering
\begin{columns}
\begin{column}{0.7\textwidth}
	\begin{figure}[!htp]
		\input{Diapos/PDEs_with_NN/Figures/Quadrature_problem/Adaptive/Adaptive_3b.tex}
		\label{fig:adaptive_1}
 	\end{figure}
\end{column}

\begin{column}{0.3\textwidth}
Training set

\vspace{2.5cm}

Validation set
\end{column}
\end{columns}
 } 

\only<4-4>{
\centering
\begin{columns}
\begin{column}{0.7\textwidth}
	\begin{figure}[!htp]
		\input{Diapos/PDEs_with_NN/Figures/Quadrature_problem/Adaptive/Adaptive_4b.tex}
		\label{fig:adaptive_1}
 	\end{figure}
\end{column}

\begin{column}{0.3\textwidth}
Training set 

\vspace{2.5cm}

Validation set
\end{column}
\end{columns}
 }

\only<5-5>{
\centering
\begin{columns}
\begin{column}{0.7\textwidth}
	\begin{figure}[!htp]
		\input{Diapos/PDEs_with_NN/Figures/Quadrature_problem/Adaptive/Adaptive_5b.tex}
		\label{fig:adaptive_1}
 	\end{figure}
\end{column}

\begin{column}{0.3\textwidth}
Training set 

\vspace{2.5cm}

Validation set
\end{column}
\end{columns}
 } 
\end{frame}


\begin{frame}{Adaptive Integration}
\vspace{0.25cm}
\begin{itemize}
\item[\tickNo] Mesh based
\vspace{0.15cm}

\item[\tickYes] Appropiate for low dimensional problems
\vspace{0.15cm}

\item[\tickYes] Allows the use of autodiff to compute $\nabla u$
\vspace{0.15cm}
\end{itemize}
\end{frame}


\begin{frame}{Piecewise-polynomial approximation}

%\begin{itemize}
%\item We define a mesh
%\end{itemize}
%
%\begin{center}
%\begin{tikzpicture}
%\draw (0,0) -- (8,0);
%\draw[red,fill=red] (0,0) circle (0.7ex);
%\draw[violet,fill=violet] (8,0) circle (0.7ex);
%\node [red] at (0,-0.4){$\Gamma_D$};
%\node [violet] at (8,-0.4){$\Gamma_N$};
%%
%\foreach \Point in {(2,0), (4,0), (6,0)}{\draw[fill=black] \Point circle (0.5ex);}
%\end{tikzpicture}
%\end{center}

\begin{itemize}
\item We define a mesh $\mathcal{T}$ composed by a  set of nodes $\{ x_{node} \}_{i=1}^{k}$
\item We select the degree $p$ of the polynomial.
\item We build the approximate piecewise solution $u^{*}_{NN,k-1} (x_{node}, u_{NN}(x_{node}))$ .
\end{itemize}

\vspace{0.5cm}
\begin{columns}
%
\begin{column}{0.45\textwidth}
\begin{tikzpicture}
    \begin{axis}[
    xlabel = {$x$},
    xmin=0,
    xmax=10,
    ymin=0,
    ymax=6,
    ylabel = {$u$},
      height=0.9*\textwidth,
      width=1*\textwidth,
    axis lines=left,
    ticks=none,
%    grid=both,
	%xtick={0,0.25,...,1},
	%ytick={0,100},
    %yticklabels={0,$a$},
    y label style={at={(-0.05,0.5)}},
%    xticklabels={-3,-1,...,5},
%    ticks=xticklabels,
    legend columns = 1,
    legend style= {at={(0.4,0.95)},draw=none,fill=none,nodes={scale=1, transform shape}}, legend cell align={left}]
    ]    
    \tikzset{ dot/.style = {circle, fill, minimum size=3pt, inner sep=0pt, outer sep=0pt}, }
% exact 
\addplot[samples=500,color=black, smooth, line width=0.5, domain=0:10] {x^0.7};	
\addlegendentry{$u_{exact}$};

%% u_NN
\addplot[samples=500,color=red, smooth, line width=0.5, domain=0:2.5] {-x^2+3.26*x };
\addlegendentry{$u_{NN}$}
\addplot[samples=10,color=blue, smooth, dashed, domain=0:2.5, line width=0.8] {1.899/2.5*x};
\addlegendentry{$u^{*}_{NN,4}$ }
%
%
%%%%%%%% WE NEED TO PUT THE FIRST THREE PLOTS DIFFERENT TO OBTAIN THE CORRECT LEGEND IN THE PLOT
%
%%% u_NN
\addplot[samples=500,color=red, smooth, line width=0.5, domain=2.5:5] {0.743*(x^2)-5.097*x +10};
\addplot[samples=500,color=red, smooth, line width=0.5, domain=5:7.5] {-0.295*(x^2)+4.0918*x -10};
\addplot[samples=500,color=red, smooth, line width=0.5, domain=7.5:10] {0.182*(x^2)-2.818*x +15};

%% u_p
\draw[color=blue, smooth, dashed, line width=0.8] (2.5,1.899) -- (5,3.085);
\draw[color=blue, smooth, dashed, line width=0.8] (5,3.085) -- (7.5,4.097);
\draw[color=blue, smooth, dashed, line width=0.8] (7.5,4.097) -- (10,5.011);

%%points
\addplot[only marks,mark=*,blue,mark size=2pt] coordinates {(2.5,1.899)(5,3.085)(7.5,4.097)(10,5.011)};

    \tikzstyle{state}=[
        draw = white,
        thick,
        fill = white,
        minimum width=15mm, 
        minimum height=4mm
    ]

\node(G)[ state,  ] at (axis cs: 6.7,1.) {\textcolor{blue}{$u^{*}_{NN,4}(x_{node})$}};
%\node(G_aux1)[anchor = north, text width=1.0] at (axis cs: 1.65,31) {};
%\node(G_aux2)[anchor = north, text width=1.0] at (axis cs: 2,31) {};
    

%\node (G1) at (axis cs: 0.28175, 19){};
%\node (G2) at (axis cs: 1.25, 46.27){};
%\node (G3) at (axis cs: 2.21825, 36.05){};
%
%\draw[] (G1) node[above, blue] {};
%\draw[] (G2) node[above, blue] {};
%\draw[] (G3) node[above, blue] {};


\path[->, blue] (axis cs: 5.8,1.2) edge (axis cs:2.7,1.8);
\path[->, blue] (G) edge (axis cs:5.15,2.9);
\path[->, blue] (G) edge (axis cs:7.5,3.8);
\path[->, blue] (G) edge (axis cs:9.9,4.8);

\end{axis}
\end{tikzpicture}
\end{column}
%
\begin{column}{0.55\textwidth}
\begin{itemize}
\item[\tickNo]  Mesh based method
\item[\tickYes] Appropriate for low dimensions
\item[\tickYes] Allows exact integration $\&$ differentiation
\item[\tickNo]  It does not allow the use of autodiff
\item[\tickYes] Exists theory about its convergence
\end{itemize}
\end{column}
\end{columns}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}[t]{Numerical Results}
\only<1-1>{
\textbf{Piecewise-linear approximation:}

Mesh with four and ten elements. One Gauss point per element. $u_{exact}=x^{0.7}$.
%\vspace{0.5cm}

\begin{minipage}{.45\textwidth}
\begin{figure}[!htp]
\centering
\input{Diapos/PDEs_with_NN/Figures/Alternatives/Ritz_model_problem_1_FD_legend.tex}
 \end{figure}
\end{minipage}%
\hspace{1.5cm}
\begin{minipage}{.35\textwidth}
\vspace{0.9cm}
\begin{figure}[!htp]
\centering
\input{Diapos/PDEs_with_NN/Figures/Alternatives/Ritz_model_problem_1_FD_loss_legend.tex}
 \end{figure}
\end{minipage}%
}

 \only<2-2>{
\textbf{Adaptive integration:}

Mesh with four elements. Three Gauss points per element. $u_{exact}=x^{0.7}$.
%\vspace{0.5cm}

\begin{minipage}{.45\textwidth}
\begin{figure}[!htp]
\centering
\input{Diapos/PDEs_with_NN/Figures/Alternatives/Ritz_model_problem_1_adap_legend.tex}
 \end{figure}
\end{minipage}%
\hspace{1.5cm}
\begin{minipage}{.35\textwidth}
\vspace{0.9cm}
\begin{figure}[!htp]
\centering
\input{Diapos/PDEs_with_NN/Figures/Alternatives/Ritz_model_problem_1_adap_loss_legend.tex}
 \end{figure}
\end{minipage}%
 }
 
 \only<3-3>{
 \textbf{Regularization:}
 Minimization of the energy $\int_0^{10} \frac{1}{2}u'(x)^2+2u(x)\,dx+u(10)$ with $u(0)=0$ and mid-point rule. $u_{exact}=x^{2}$.
 \vspace{0.5cm}
% \begin{figure}[!htp]
% \centering
%    \input{Figures_new/Jamie_legend/Implementation_1/Ritz_model_problem_2_Imp1_NOREG_legend.tex}
%    	\hspace{1cm}
%	\input{Figures_new/Jamie_legend/Implementation_1/Ritz_model_problem_2_Imp1_NOREG_loss_R_legend.tex}
%  \end{figure}
  
  \begin{minipage}{.45\textwidth}
\begin{figure}[!htp]
\centering
\input{Diapos/PDEs_with_NN/Figures/Alternatives/Ritz_model_problem_2_Imp1_NOREG_legend.tex}
 \end{figure}
\end{minipage}%
\hspace{1.5cm}
\begin{minipage}{.35\textwidth}
\vspace{-0.25cm}
\begin{figure}[!htp]
\centering
\input{Diapos/PDEs_with_NN/Figures/Alternatives/Ritz_model_problem_2_Imp1_NOREG_loss_R_legend.tex}
 \end{figure}
\end{minipage}%
 }
 
\only<4-4>{
 \textbf{Regularization:}
 Minimization of the energy $\int_0^{10} \frac{1}{2}u'(x)^2+2u(x)\,dx+u(10)$ with $u(0)=0$ and mid-point rule. $u_{exact}=x^{2}$.
 \vspace{0.35cm}
 
\begin{minipage}{.45\textwidth}
\begin{figure}[!htp]
\centering
\input{Diapos/PDEs_with_NN/Figures/Alternatives/Ritz_model_problem_2_Imp1_REG_legend.tex}
 \end{figure}
\end{minipage}%
\hspace{1.5cm}
\begin{minipage}{.35\textwidth}
\vspace{0.3cm}
\begin{figure}[!htp]
\centering
\input{Diapos/PDEs_with_NN/Figures/Alternatives/Ritz_model_problem_2_Imp1_REG_loss_R_legend.tex}
 \end{figure}
\end{minipage}%
 }
 \end{frame}


\begin{frame}{Deep Neural Networks for Solving PDEs}
\begin{itemize}
\item Quadrature errors appear when solving PDEs using DL methods.
\vspace{0.5cm}
\item Selecting an adequate quadrature rule is critical.
\vspace{0.5cm}
\item For high dimensions Monte Carlo is adequate.
\vspace{0.5cm}
\item We propose adaptive integration for low dimensions.
\end{itemize}
\end{frame}